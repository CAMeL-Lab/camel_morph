import sys
import os
import argparse
import json
from tqdm import tqdm
import pickle
import random
import re
import multiprocessing
import cProfile, pstats
import shutil
import numpy as np

import eval_utils


# Custom objects know their class.
# Function objects seem to know way too much, including modules.
# Exclude modules as well.

essential_keys = ['diac', 'lex', 'pos', 'asp', 'mod', 'vox', 'per', 'num', 'gen',
                  'cas', 'stt', 'prc0', 'prc1', 'prc2', 'prc3', 'enc0']
feats_oblig = ['asp', 'mod', 'vox', 'per', 'num', 'gen', 'cas', 'stt']
essential_keys_no_lex_pos = [k for k in essential_keys if k not in ['diac', 'lex', 'pos']]

parser = argparse.ArgumentParser()
parser.add_argument("-output_dir", default='eval_files',
                    type=str, help="Path of the directory to output evaluation results.")
parser.add_argument("-config_file", default='configs/config.json',
                    type=str, help="Config file specifying which sheets to use.")
parser.add_argument("-db_dir", default='databases',
                        type=str, help="Path of the directory to load the DB from.")
parser.add_argument("-msa_config_name", default='all_aspects_msa',
                    type=str, help="Config name which specifies the path of the MSA Camel DB.")
parser.add_argument("-msa_baseline_db", default='eval_files/calima-msa-s31_0.4.2.utf8.db',
                    type=str, help="Path of the MSA baseline DB file we will be comparing against.")
parser.add_argument("-multiprocessing", default=False, action='store_true',
                    help="Whether or not to use multiprocessing.")
parser.add_argument("-report_dir", default='eval_files/report_default',
                    type=str, help="Paths of the directory containing partial reports generated by the full generative evaluation.")
parser.add_argument("-prev_report_dir", default='eval_files/report_default',
                    type=str, help="Paths of the directory containing the previous partial reports generated by the full generative evaluation for possible analyses.")
parser.add_argument("-test_mode", default=False, action='store_true',
                    help="Only test mode.")
parser.add_argument("-profiling", default=False, action='store_true',
                    help="Run profiling.")
parser.add_argument("-chunk", default=100,
                    type=int, help="Length of chunks that get processed in parallel and then aggregated.")
parser.add_argument("-n_cpu", default=8,
                    type=int, help="Number of cores to use.")
parser.add_argument("-n", default=100,
                    type=int, help="Number of inputs to the two compared systems.")
parser.add_argument("-camel_tools", default='local', choices=['local', 'official'],
                    type=str, help="Path of the directory containing the camel_tools modules.")
args = parser.parse_args()

random.seed(42)

with open(args.config_file) as f:
    config = json.load(f)
    config_local = config['local']
    config_msa = config_local[args.msa_config_name]

if args.camel_tools == 'local':
    camel_tools_dir = config['global']['camel_tools']
    sys.path.insert(0, camel_tools_dir)

from camel_tools.morphology.database import MorphologyDB
from camel_tools.morphology.generator import Generator
from camel_tools.utils.charmap import CharMapper

bw2ar = CharMapper.builtin_mapper('bw2ar')
ar2bw = CharMapper.builtin_mapper('ar2bw')

sukun_ar, fatHa_ar = bw2ar('o'), bw2ar('a')
sukun_regex = re.compile(sukun_ar)
aA_regex = re.compile(f'(?<!^[وف]){fatHa_ar}ا')


def get_all_lemmas_from_db(db):
    lemma_pos = set()
    for match, analyses in db.stem_hash.items():
        for cat, analysis in analyses:
            lemma_pos.add((analysis['lex'], analysis['pos']))
    return lemma_pos


def _preprocess_lex_features(analysis):
    for k in ['lex', 'diac']:
        analysis[k] = sukun_regex.sub('', analysis[k])
        analysis[k] = aA_regex.sub('A', analysis[k])


def generate_all_possible_words_from_lemma(id_lemma_pos, oblig_spec=False):
    if not args.multiprocessing:
        global eval_with_clitics, failed
        global accuracy_matrix_camel, accuracy_matrix_baseline
    else:
        eval_with_clitics, failed,  = {}, {}
        accuracy_matrix_camel = np.zeros((1, len(index2analysis)), dtype='bool')
        accuracy_matrix_baseline = np.zeros((1, len(index2analysis)), dtype='bool')
    
    lemma_id, (lemma_ar, pos) = id_lemma_pos
    generations_baseline, generations_camel = [], []
    
    if oblig_spec:
        for feats_oblig in tqdm(pos2obligfeats[pos]):
            for feats_clitic in pos2cliticfeats[pos]:
                feats_all = {**feats_oblig, **feats_clitic}
                try:
                    generations_baseline += generator_baseline.generate(lemma_ar, feats_all)
                except:
                    failed.setdefault('baseline', []).append((lemma_ar, feats_all))
                if feats_all.get('prc0') not in ['mA_neg', 'lA_neg']:
                    try:
                        generations_camel += generator_camel.generate(lemma_ar, feats_all)
                    except:
                        failed.setdefault('camel', []).append((lemma_ar, feats_all))
    else:
        for feats_clitic in pos2cliticfeats[pos]:
            try:
                generations_baseline += generator_baseline.generate(lemma_ar, feats_clitic)
            except:
                failed.setdefault('baseline', []).append((lemma_ar, feats_clitic))
            if feats_clitic.get('prc0') not in ['mA_neg', 'lA_neg']:
                try:
                    generations_ = generator_camel.generate(lemma_ar, feats_clitic)
                    generations_camel += generations_
                except:
                    failed.setdefault('camel', []).append((lemma_ar, feats_clitic))

    
    generations_baseline_ = {}
    for g in generations_baseline:
        _preprocess_lex_features(g)
        key = tuple([g.get(k, 'na') for k in essential_keys_no_lex_pos])
        generations_baseline_.setdefault(key, []).append((g['lex'], g['diac'], g['pos']))
    
    generations_camel_ = {}
    for g in generations_camel:
        _preprocess_lex_features(g)
        key = tuple([g.get(k, 'na') for k in essential_keys_no_lex_pos])
        generations_camel_.setdefault(key, []).append((g['lex'], g['diac'], g['pos']))

    generations_camel_set, generations_baseline_set = set(generations_camel_), set(generations_baseline_)
    camel_minus_baseline = generations_camel_set - generations_baseline_set
    baseline_minus_camel = generations_baseline_set - generations_camel_set
    intersection = generations_camel_set & generations_baseline_set
    
    for k in camel_minus_baseline:
        k_ = '+'.join(k)
        eval_with_clitics.setdefault('camel', {}).setdefault(k_, []).append(lemma_id)
        if not args.multiprocessing:
            accuracy_matrix_camel[lemma_id][analysis2index[k_]] = True
        else:
            accuracy_matrix_camel[0][analysis2index[k_]] = True
    for k in baseline_minus_camel:
        k_ = '+'.join(k)
        eval_with_clitics.setdefault('baseline', {}).setdefault(k_, []).append(lemma_id)
        if not args.multiprocessing:
            accuracy_matrix_baseline[lemma_id][analysis2index[k_]] = True
        else:
            accuracy_matrix_baseline[0][analysis2index[k_]] = True
    for k in intersection:
        k_ = '+'.join(k)
        if not args.multiprocessing:
            accuracy_matrix_camel[lemma_id][analysis2index[k_]] = True
            accuracy_matrix_baseline[lemma_id][analysis2index[k_]] = True
        else:
            accuracy_matrix_camel[0][analysis2index[k_]] = True
            accuracy_matrix_baseline[0][analysis2index[k_]] = True
        info = eval_with_clitics.setdefault('both', {}).setdefault(
            k_, {'matching': 0, 'total': 0, 'intersect_baseline': [0, []], 'intersect_camel': [0, []], 'no_intersect': [0, []]})
        lemma_diac_pos_baseline_set = set(generations_baseline_[k])
        lemma_diac_pos_camel_set = set(generations_camel_[k])
        info['matching'] += len(lemma_diac_pos_camel_set & lemma_diac_pos_baseline_set)
        info['total'] += len(lemma_diac_pos_baseline_set)
        
        camel_baseline_lex_intersect = lemma_diac_pos_camel_set & lemma_diac_pos_baseline_set
        
        camel_minus_baseline_lex = lemma_diac_pos_camel_set - lemma_diac_pos_baseline_set
        if camel_baseline_lex_intersect:
            if camel_minus_baseline_lex:
                info['intersect_camel'][0] += len(camel_minus_baseline_lex)
                info['intersect_camel'][1].append(lemma_id)
            
            baseline_minus_camel_lex = lemma_diac_pos_baseline_set - lemma_diac_pos_camel_set
            if baseline_minus_camel_lex:
                info['intersect_baseline'][0] += len(baseline_minus_camel_lex)
                info['intersect_baseline'][1].append(lemma_id)
        else:
            info['no_intersect'][0] += len(lemma_diac_pos_baseline_set)
            info['no_intersect'][1].append(lemma_id)

    return lemma_id, eval_with_clitics, accuracy_matrix_camel, accuracy_matrix_baseline


path_db_baseline = args.msa_baseline_db
db_baseline = MorphologyDB(path_db_baseline)

db_baseline_gen = MorphologyDB(path_db_baseline, flags='g')
generator_baseline = Generator(db_baseline_gen)

path_db_camel = os.path.join(args.db_dir, config_msa['db'])
db_camel_gen = MorphologyDB(path_db_camel, flags='g')
generator_camel = Generator(db_camel_gen)

DEFINES = {k: v if v is None else [vv for vv in v if vv != 'na']
           for k, v in generator_baseline._db.defines.items()}

pos2cliticfeats = eval_utils.get_pos2clitic_combs(db_baseline)
pos2obligfeats = eval_utils._get_pos2obligfeats(db_baseline)

lemmas_pos = list(get_all_lemmas_from_db(db_baseline))
lemmas_pos = [lemma_pos for lemma_pos in lemmas_pos
              if lemma_pos[-1] == 'verb' and lemma_pos[0] == 'هَنّ'][:args.n]
lemmas_pos = [(i, lemma_pos) for i, lemma_pos in enumerate(lemmas_pos)]

previous_report = eval_utils.load_full_report(args.prev_report_dir)
if previous_report:
    index2analysis = eval_utils.get_union_of_analyses(previous_report)
else:
    raise NotImplementedError
analysis2index = {analysis: i for i, analysis in enumerate(index2analysis)}
accuracy_matrix_baseline = np.zeros((len(lemmas_pos), len(index2analysis)), dtype='bool')
accuracy_matrix_camel = np.zeros((len(lemmas_pos), len(index2analysis)), dtype='bool')

eval_with_clitics = {}
failed = {}

if args.profiling:
    profiler = cProfile.Profile()
    profiler.enable()

if __name__ == "__main__":
    if os.path.isdir(args.report_dir):
        shutil.rmtree(args.report_dir)
    os.makedirs(args.report_dir)

    with open(os.path.join(args.report_dir, 'lemmas_pos.pkl'), 'wb') as f:
        pickle.dump(lemmas_pos, f)
    
    if args.multiprocessing:
        lemma_chunked = [lemmas_pos[i:i + args.chunk]
                            for i in range(0, len(lemmas_pos), args.chunk)]
        dump_count = 0
        for i_chunk, chunk in enumerate(tqdm(lemma_chunked)):
            with multiprocessing.Pool(args.n_cpu) as p:
                results = list(p.imap(generate_all_possible_words_from_lemma, chunk))
            
            for lemma_id, eval_with_clitics_, accuracy_matrix_camel_, accuracy_matrix_baseline_ in results:
                eval_utils.join_reports(
                    main_report=eval_with_clitics, report_to_add=eval_with_clitics_)
                accuracy_matrix_baseline[lemma_id] = accuracy_matrix_baseline_
                accuracy_matrix_camel[lemma_id] = accuracy_matrix_camel_
            
            if int(len(lemma_chunked) / 4) == 0 or i_chunk % int(len(lemma_chunked) / 4) == 0 \
                or i_chunk == len(lemma_chunked) - 1:
                with open(os.path.join(args.report_dir, f'{str(dump_count)}.pkl'), 'wb') as f:
                    pickle.dump(eval_with_clitics, f)
                dump_count += 1
                eval_with_clitics = {}
    else:
        results = []
        for id_lemma_pos in tqdm(lemmas_pos):
            generate_all_possible_words_from_lemma(id_lemma_pos)

        with open(os.path.join(args.report_dir, 'results_serial.pkl'), 'wb') as f:
            pickle.dump(eval_with_clitics, f)

    with open(os.path.join(args.report_dir, 'failed.pkl'), 'wb') as f:
        pickle.dump(failed, f)
    
    np.save(os.path.join(args.report_dir, 'accuracy_matrix_baseline'), accuracy_matrix_baseline)
    np.save(os.path.join(args.report_dir, 'accuracy_matrix_camel'), accuracy_matrix_camel)
    with open(os.path.join(args.report_dir, 'index2analysis.pkl'), 'wb') as f:
        pickle.dump(index2analysis, f)