import sys
import argparse
import json
import os
import numpy as np
from tqdm import tqdm
from tabulate import tabulate
import json
from collections import OrderedDict

import eval_utils
from eval_utils import color, bold, underline
from row_classes import *

parser = argparse.ArgumentParser()
parser.add_argument("-config_file", default='eval_files/report_default',
                    type=str, help="Config file specifying which sheets to use.")
parser.add_argument("-pos", required=True,
                    type=str, help="Part-of-speech to perform the evaluation on.")
parser.add_argument("-db_baseline", default='eval_files/calima-msa-s31_0.4.2.utf8.db',
                    type=str, help="Path of the MSA baseline DB file we will be comparing against.")
parser.add_argument("-db_system", default='databases/camel-morph-msa/XYZ_msa_all_v1.0.db',
                    type=str, help="Path of the MSA baseline DB file we will be comparing against.")
parser.add_argument("-report_dir", default='eval_files/report_default',
                    type=str, help="Paths of the directory containing partial reports generated by the full generative evaluation.")
parser.add_argument("-baseline_specific_feat_combs", default='',
                    type=str, help="Object containing the individual feat:value pairs that are only specific to the baseline.")
parser.add_argument("-system_specific_feat_combs", default='',
                    type=str, help="Object containing the individual feat:value pairs that are only specific to the system.")

parser.add_argument("-baseline_name", default='Calima',
                    type=str, help="Name that will appear in the report for the baseline.")
parser.add_argument("-system_name", default='Camel',
                    type=str, help="Name that will appear in the report for the system.")
parser.add_argument("-camel_tools", default='local', choices=['local', 'official'],
                    type=str, help="Path of the directory containing the camel_tools modules.")
args = parser.parse_args()

with open('configs/config_default.json') as f:
    config = json.load(f)

if args.camel_tools == 'local':
    camel_tools_dir = config['global']['camel_tools']
    sys.path.insert(0, camel_tools_dir)

from camel_tools.morphology.database import MorphologyDB
from camel_tools.morphology.generator import Generator
from camel_tools.utils.charmap import CharMapper

bw2ar = CharMapper.builtin_mapper('bw2ar')
ar2bw = CharMapper.builtin_mapper('ar2bw')


def get_group2categorization(feat_value_pairs, feat2index, diac_mat, index2analysis, specific_feat_combs):
        # Contains for each feat:value the analyses (from possible combinations) that contain it
        feat_value2queries = {}
        for feat, value, pos in feat_value_pairs:
            #NOTE: not using POS, might be problematic for OTHER
            for i, feats in enumerate(index2analysis):
                if feats[feat2index[feat]] == value:
                    feat_value2queries.setdefault((feat, value), []).append(i)
        # Contains for each feat:value the number of slots it occupies
        feat_value2slots = {}
        for (feat, value), queries in feat_value2queries.items():
            queries = np.array(queries)
            queries_valie_slots = diac_mat[:, queries]
            feat_value2slots[(feat, value)] = np.sum(queries_valie_slots)
        # Contains all the feat_combs in which the feat:value pairs participate
        feat_combs_group_1_indexes = set.union(*map(set, feat_value2queries.values()))
        # Contains all the feat_combs which do not have any of these feat:value pairs
        # but which are still unique to that system. These might either be invalid OR
        # mappable to one(s) in that of another system.
        feat_combs_group_2_indexes = [i for i in range(len(index2analysis))
                                        if i not in feat_combs_group_1_indexes]
        feat_combs_group_2 = [feats for i, feats in enumerate(index2analysis)
                                        if i in feat_combs_group_2_indexes]
        group_2_categorization = {}
        for feat_comb in feat_combs_group_2:
            for info in specific_feat_combs:
                feats_dict = info['feats_dict']
                invalid = True
                for f, v_rule in feats_dict.items():
                    v = feat_comb[feat2index[f]]
                    match = False
                    for v_rule_ in v_rule.split('+'):
                        match = match or (v_rule_[0] == '!' and v != v_rule_[1:] or
                                        v_rule_[0] != '!' and v == v_rule_)
                    invalid = invalid and match
                if invalid:
                    break
            if invalid:
                group_2_categorization.setdefault(
                    ' '.join(sorted(f'{f}:{v}' for f, v in info['feats_dict'].items())), []).append(feat_comb)
        assert sum(len(feats) for feats in group_2_categorization.values()) == len(feat_combs_group_2)
        assert len(specific_feat_combs) == len(group_2_categorization)
        
        return group_2_categorization
        

def generate_examples(index2lemmas_pos, index2analysis,
                     match_comb_mask=None, match_comb_indexes=None):
    if match_comb_mask is not None:
        match_comb_indexes = np.where(match_comb_mask)
    example_coord = (match_comb_indexes[0][0], match_comb_indexes[1][0])
    lemma, pos = index2lemmas_pos[example_coord[0]]
    feats = index2analysis[example_coord[1]]
    try:
        example_forms_system = generator_system.generate(
            lemma, eval_utils.construct_feats(feats, pos))
        example_forms_system = ','.join(
            set(eval_utils.preprocess_lex_features(form, True)['diac']
                for form in example_forms_system))
        if example_forms_system:
            example_forms_system += bold(color('✓', 'green'))
        else:
            example_forms_system = bold(color('x', 'fail'))
    except:
        example_forms_system = ''
    try:
        example_forms_baseline = generator_baseline.generate(
            lemma, eval_utils.construct_feats(feats, pos), legacy=True)
        example_forms_baseline = ','.join(
            set(eval_utils.preprocess_lex_features(form, True)['diac']
                for form in example_forms_baseline))
        if example_forms_baseline:
            example_forms_baseline += bold(color('✓', 'green'))
        else:
            example_forms_baseline = bold(color('x', 'fail'))
    except:
        example_forms_baseline = ''

    examples_str = (bold(color('lex:', 'warning')) + ar2bw(lemma) + bold(color(' •', 'header')) + '\n' +
                   bold(color('feats:', 'warning')) + '+'.join(feats) + bold(color(' •', 'header')) + '\n' +
                   bold(color(f'{args.system_name.lower()}:', 'warning')) + ar2bw(example_forms_system) + '\n' +
                   bold(color(f'{args.baseline_name.lower()}:', 'warning')) + ar2bw(example_forms_baseline))
    
    return examples_str


def section_title():
    report_title = f"Evaluation Report - {' '.join(pos.upper() for pos in POS)}"
    try:
        terminal_size_col = os.get_terminal_size().columns
    except:
        terminal_size_col = len(report_title)
    print()
    print('=' * terminal_size_col)
    print(report_title)
    print('=' * terminal_size_col)
    print()
    baseline_path = color(bold(args.db_baseline), 'cyan')
    system_path = color(bold(args.db_system), 'cyan')
    print(bold(underline('DBs used for analysis')))
    print(f'{args.baseline_name}: ' + color(bold(args.db_baseline), 'cyan'))
    print(f'{args.system_name}: ' + color(bold(args.db_system), 'cyan'))
    print()


def section_lemma_overlap():
    print(bold(underline(f'Verb Lemmas overlap between {args.baseline_name} and {args.system_name}')))
    print()
    lemmas_pos_baseline = eval_utils.get_all_lemmas_from_db(db_baseline)
    lemmas_baseline = set([lemma_pos[0] for lemma_pos in lemmas_pos_baseline if lemma_pos[1] in POS])
    lemmas_pos_system = eval_utils.get_all_lemmas_from_db(MorphologyDB(args.db_system))
    lemmas_system = set([lemma_pos[0] for lemma_pos in lemmas_pos_system if lemma_pos[1] in POS])
    rows = []
    header = ['A . B', 'Result', '# lemmas', '(%)', 'Lemmas']
    lemmas_baseline_only = lemmas_baseline - lemmas_system
    lemmas_system_only = lemmas_system - lemmas_baseline
    lemmas_intersect = lemmas_system & lemmas_baseline
    lemmas_union = lemmas_system | lemmas_baseline
    rows.append([f'{args.baseline_name} - {args.system_name}',
                f'{len(lemmas_baseline_only):,}',
                f'{len(lemmas_baseline):,} in A',
                f'{len(lemmas_baseline_only) / len(lemmas_baseline):.2%}',
                ' '.join(sorted(map(ar2bw, lemmas_baseline_only)))])
    rows.append([f'{args.system_name} - {args.baseline_name}',
                f'{len(lemmas_system_only):,}',
                f'{len(lemmas_system):,} in A',
                f'{len(lemmas_system_only) / len(lemmas_system):.2%}',
                ' '.join(sorted(map(ar2bw, lemmas_system_only)))])
    rows.append([f'{args.system_name} ∩ {args.baseline_name}',
                bold(color(f'{len(lemmas_intersect):,}', 'green')),
                f'{len(lemmas_union):,} in A ∪ B',
                f'{len(lemmas_intersect) / len(lemmas_union):.2%}',
                '-'])
    print(tabulate(rows, tablefmt='fancy_grid', headers=header, maxcolwidths=[None, None, None, None, 100]))
    print()


def section_high_level_overlap_stats():
    print(bold(underline(f'Overlap statistics of generated diacs between {args.baseline_name} and {args.system_name}')))
    print()
    rows = []
    slots_total = num_valid_feats * num_valid_lemmas
    slots_filled_mask = mask_not_equal_0_system | mask_not_equal_0_baseline
    slots_filled_total = int(np.sum(slots_filled_mask))

    examples_str = generate_examples(index2lemmas_pos_inter, index2analysis_inter, slots_filled_mask)
    rows.append(['Number of slots filled by at least one of the systems (0-x, x-0, x-y)',
                bold(color(f'{slots_filled_total:,}', 'warning')),
                f'{slots_filled_total/slots_total:.0%}',
                examples_str])
    examples_str = generate_examples(index2lemmas_pos_inter, index2analysis_inter, ~slots_filled_mask)
    rows.append(['Number of slots filled by none of the systems (0-0)',
                f'{slots_total - slots_filled_total:,}',
                f'{(slots_total - slots_filled_total)/slots_total:.0%}',
                examples_str])
    rows.append(['Total number of slots per system',
                f'{slots_total:,}' + '\n(' + bold(color(f'{num_valid_lemmas:,} ', 'green')) + '× ' +
                bold(color(f'{num_valid_feats:,}', 'green')) + ')',
                f'{1:.0%}', '-'])
    assert len(diac_mat_baseline_inter) == len(diac_mat_system_inter)
    print('Number of lemmas evaluated on: ' + bold(color(f'{len(diac_mat_baseline_inter):,}', 'green')) +
        f' ({args.system_name} ∩ {args.baseline_name})')
    print('Total number of feature combinations across both systems: ' + bold(color(f'{num_valid_feats:,}', 'green')))
    print(tabulate(rows, tablefmt='fancy_grid', maxcolwidths=[40, None, None, 60]))
    print()


def section_shared_combinations_high_level_stats():
    print(bold(underline(f'Distribution of feature combination availability across systems for ')) +
      bold(underline(color('SHARED', 'orange'))) + bold(underline(f' feature combination pairs (0-x, x-0, x-y)')))

    notes = color(f"""
    Notes:
        - # diac here is the number of unique diacs generated, and not the number of analyses generated which could generally be more.
        - The meaning of the dash ("-") is anything but zero.
        - A "slot" is a matrix cell representing a lemma and a feature combinatinon from which one a more diacs were generated.
        - "Slot space" means we are counting number of slots while in diac space were are counting number of diacs. This effectively means that
        the # diac is taken as 1 for the purpose of recall analysis.
        - Slots column is the number of feature combinations that both systems were able to generate for listed lemmas with the specified number of diacs.
        - Lemmas column is the number of lemmas with which at least one feature combination generates with the specified number of diacs.
        - Top number in recall distribution (last columns) indicates recall (diac space) by {args.system_name} of {args.baseline_name} and bottom is in slot space
        (displayed only if different). Total recall in slot space basically represents the sum of all categories (in slot space) minus no_intersect.
        - All total recall values are micro-averaged.
    """, 'warning')
    print(notes)
    print()

    header = OrderedDict([
        ((f'# diac ({args.baseline_name})', 8), ('num_diac_baseline',)),
        ((f'# diac ({args.system_name})', 7), ('num_diac_system',)),
        (('Slots', None), ('match_comb_mask_str',)),
        (('Lemmas', None), ('num_lemmas_match_str',)),
        (('Feat combs', 7), ('num_feats_match_str',)),
        (('Example', 60), ('example_str',))
    ])

    combinations = [
        dict(baseline=0, system='≥1',
             match_comb_mask=(diac_mat_baseline_inter == 0) & (diac_mat_system_inter != 0)),
        dict(baseline='≥1', system=0,
             match_comb_mask=(diac_mat_baseline_inter != 0) & (diac_mat_system_inter == 0)),
        dict(baseline='≥1', system='≥1',
             match_comb_mask=(diac_mat_baseline_inter != 0) & (diac_mat_system_inter != 0),
             slots_color='cyan', lemmas_feats_color='orange'),
        dict(baseline='≥0', system='≥0',
             match_comb_mask=(diac_mat_baseline_inter != 0) | (diac_mat_system_inter == 0),
             slots_color='warning', lemmas_feats_color='green')
    ]

    match_total = int(np.sum(mask_not_equal_0_baseline | mask_not_equal_0_system))

    rows = []
    for combination in tqdm(combinations, ncols=100):
        row = DiacCombinationRow(combination, match_total,
                                num_valid_lemmas, num_valid_feats,
                                diac_mat_baseline=diac_mat_baseline_inter,
                                diac_mat_system=diac_mat_system_inter,
                                system_only_mat=system_only_mat_inter,
                                baseline_only_mat=baseline_only_mat_inter,
                                no_intersect_mat=no_intersect_mat_inter,
                                index2lemmas_pos=index2lemmas_pos_inter,
                                index2analysis=index2analysis_inter)
        if row.match_comb_mask_sum:
            row.example_str = generate_examples(
                index2lemmas_pos_inter, index2analysis_inter, combination['match_comb_mask'])
            rows.append(row)

    for row in rows:
        row.val_and_perc_str('match_comb_mask', row.slots_color)
        for attr in ['num_lemmas_match', 'num_feats_match']:
            row.val_and_perc_str(attr, row.lemmas_feats_color)

    rows = sorted(rows, key=lambda row: row.match_comb_mask_sum
                if row.num_diac_baseline != '≥0' else -1,
                reverse=True)
    rows = [[getattr(row, var[0]) for var in header.values()] for row in rows]
    rows[-1] = [bold(v) for v in rows[-1]]

    print(tabulate(rows, tablefmt='fancy_grid', headers=[h[0] for h in header],
                maxheadercolwidths=[h[1] for h in header]))
    print()


def section_x_y_breakdown():
    print(bold(underline(f'Summary breakdown of the x-y set (coverage of {args.baseline_name} by {args.system_name})')))
    notes = color(f"""
        Notes:
        - The five columns (1) No intersec (2) Exact match (3) Calima super (4) Camel Super (5) Intersec are a distribution of
        the recall from the system's side. So for example, 99% in Calima super and 49.5% in the last column (Recall baseline (micro))
        means that 99% of slots in Camel for that number of diacs combination match the baseline, while 49.5% is an aggregate (micro) as
        seen from the baseline's side because in this case the baseline diacs are a superset of the system's.
        """, 'warning')
    print(notes)

    combinations = [
        dict(baseline=1, system='>1',
            match_comb_mask=((diac_mat_baseline_inter == 1) &
                            (diac_mat_system_inter > 1)),
            slots_color='cyan', diacs_color='green'),
        dict(baseline='>1', system=1,
            match_comb_mask=((diac_mat_baseline_inter > 1) &
                            (diac_mat_system_inter == 1)),
            slots_color='cyan', diacs_color='green'),

        dict(baseline=1, system=1,
            match_comb_mask=((diac_mat_baseline_inter == 1) &
                            (diac_mat_system_inter == 1)),
            slots_color='cyan', diacs_color='green'),
        dict(baseline='x>1', system='y>1',
            match_comb_mask=((diac_mat_baseline_inter > 1) &
                            (diac_mat_system_inter > 1) &
                            (diac_mat_system_inter != diac_mat_baseline_inter)),
            slots_color='cyan', diacs_color='green'),

        dict(baseline='x>1', system='x>1',
            match_comb_mask=((diac_mat_baseline_inter > 1) &
                            (diac_mat_system_inter > 1) &
                            (diac_mat_system_inter == diac_mat_baseline_inter)),
            slots_color='cyan', diacs_color='green'),
        dict(baseline='≥1', system='≥1',
            match_comb_mask=((diac_mat_baseline_inter != 0) &
                            (diac_mat_system_inter != 0)),
            slots_color='cyan', diacs_color='green', lemmas_feats_color='orange')
    ]

    header = OrderedDict([
        ((f'# diac ({args.baseline_name})', 8), ('num_diac_baseline', 8)),
        ((f'# diac ({args.system_name})', 7), ('num_diac_system', 7)),
        (('Slots', None), ('match_comb_mask_str', None)),
        (('Lemmas', None), ('num_lemmas_match_str', None)),
        (('Feat combs', 9), ('num_feats_match_str', 9)),
        (('Example', 60), ('example_str', 60)),
        (('No intersec', 8), ('recall_no_intersect_str', 8)),
        (('Exact match', 7), ('recall_exact_match_str', 7)),
        ((f'{args.baseline_name} super', 8), ('recall_baseline_superset_str', 8)),
        ((f'{args.system_name} super', 7), ('recall_system_superset_str', 7)),
        (('Intersec', 8), ('recall_intersect_str', 8)),
        ((f'Recall {args.baseline_name} (micro)', 8), (f'recall_baseline_str', 8)),
        ((f'Recall {args.system_name} (micro)', 8), (f'recall_system_str', 8)),
    ])

    match_x_y_total = int(np.sum(mask_not_equal_0_baseline & mask_not_equal_0_system))

    rows = []
    for combination in tqdm(combinations, ncols=100):
        row = DiacCombinationRow(combination, match_x_y_total,
                                num_valid_lemmas, num_valid_feats,
                                diac_mat_baseline=diac_mat_baseline_inter,
                                diac_mat_system=diac_mat_system_inter,
                                system_only_mat=system_only_mat_inter,
                                baseline_only_mat=baseline_only_mat_inter,
                                no_intersect_mat=no_intersect_mat_inter,
                                index2lemmas_pos=index2lemmas_pos_inter,
                                index2analysis=index2analysis_inter)
        if row.match_comb_mask_sum:
            row.example_str = generate_examples(
                index2lemmas_pos_inter, index2analysis_inter, combination['match_comb_mask'])
            row.val_and_perc_str('match_comb_mask', row.slots_color)
            for attr in ['num_lemmas_match', 'num_feats_match']:
                row.val_and_perc_str(attr, row.lemmas_feats_color)
            rows.append(row)

    rows = sorted(rows, key=lambda row: row.match_comb_mask_sum
                if row.num_diac_baseline != '≥1' else -1,
                reverse=True)
    rows = [[getattr(row, var[0]) for var in header.values()] for row in rows]
    rows[-1] = [bold(v) for v in rows[-1]]

    print(tabulate(rows, tablefmt='fancy_grid', headers=[h[0] for h in header],
                maxheadercolwidths=[h[1] for h in header]))
    print()


def section_unshared_combinations_high_level_stats():
    print(bold(underline(f'Distribution of feature combination availability across systems for ')) +
        bold(underline(color('UNSHARED', 'orange'))) + bold(underline(f' feature combination pairs (0-x, x-0)')))
    notes = color(f"""
    Notes:
    - The unshared feature combination pairs can be divided into two groups:
        1. The ones which contain individual feat:value pairs that are never seen in the opposite systems.
        2. The ones which contain sub-combinations of feat:value pairs that, while seen individually in the opposite system,
        are never seen together in the latter.
    - The last column of the below table lists the ones of the first group. Second group is dealt with in the next section.
    """, 'warning')
    print(notes)
    rows = []
    header = [f'# diac ({args.baseline_name})', f'# diac ({args.system_name})',
            'Slots', 'Lemmas', 'Feats', 'Example', 'Unshared feats']
    
    pos2feat_value_pairs_baseline = POS2FEAT_VALUE_PAIRS['baseline']
    feat_value_pairs_baseline = set([tuple(feat_value_pair.split(':')) + (pos,)
                                    for pos, feat_value_pairs in pos2feat_value_pairs_baseline.items()
                                    for feat_value_pair in feat_value_pairs])
    pos2feat_value_pairs_system = POS2FEAT_VALUE_PAIRS['system']
    feat_value_pairs_system = set([tuple(feat_value_pair.split(':')) + (pos,)
                                for pos, feat_value_pairs in pos2feat_value_pairs_system.items()
                                for feat_value_pair in feat_value_pairs])
    # This is not intersection of the feat:value pairs of the intersction matrix feat_combs
    # but is the intersection of common feat:value pairs in both systems (whether they occur
    # in the above or not e.g., >a_ques does not occur in the 3828 combs intersection for verbs
    # but occurs in both systems individually, hence it will occur in the below variable).
    # Might need to change this if we want to enable an automatic discovery of mismatching feat:value
    # pairs.
    feat_value_pairs_intersect = feat_value_pairs_baseline & feat_value_pairs_system
    feat_value_pairs_baseline_only = feat_value_pairs_baseline - feat_value_pairs_intersect
    feat_value_pairs_system_only = feat_value_pairs_system - feat_value_pairs_intersect

    feat2index = {feat: i for i, feat in enumerate(eval_utils.essential_keys_no_lex_pos)}

    if args.baseline_specific_feat_combs:
        with open(os.path.join(args.report_dir, args.baseline_specific_feat_combs)) as f:
            specific_feat_combs_baseline = json.load(f)
        group_2_categorization_bo = get_group2categorization(feat_value_pairs_baseline_only,
                                                             feat2index,
                                                             diac_mat_baseline_only,
                                                             index2analysis_bo,
                                                             specific_feat_combs_baseline)
        feat_combs_indexes_bo = np.array([analysis2index_bo[feat_comb]
                                            for feat_combs in group_2_categorization_bo.values()
                                            for feat_comb in feat_combs])
        group_2_mask_bo = diac_mat_baseline_only[:, feat_combs_indexes_bo] != 0
        group_2_sum_bo = int(np.sum(group_2_mask_bo))
    else:
        specific_feat_combs_baseline = None
    if args.system_specific_feat_combs:
        with open(os.path.join(args.report_dir, args.system_specific_feat_combs)) as f:
            specific_feat_combs_system = json.load(f)
        group_2_categorization_so = get_group2categorization(feat_value_pairs_system_only,
                                                             feat2index,
                                                             diac_mat_system_only,
                                                             index2analysis_so,
                                                             specific_feat_combs_system)
        feat_combs_indexes_so = np.array([analysis2index_so[feat_comb]
                                            for feat_combs in group_2_categorization_so.values()
                                            for feat_comb in feat_combs])
        group_2_mask_so = diac_mat_system_only[:, feat_combs_indexes_so] != 0
        group_2_sum_so = int(np.sum(group_2_mask_so))
    else:
        specific_feat_combs_system = None

    def get_feat_value_pairs_str(feat_value_pairs):
        pos2feat_value_pairs = {}
        for feat, value, pos in feat_value_pairs:
            pos2feat_value_pairs.setdefault(pos, set()).add(f'{feat}:{value}')
        
        feat_value_pairs_str = '; '.join(pos.upper() + '(' + ' '.join(sorted(feat_value)) + ')'
                                    for pos, feat_value in pos2feat_value_pairs.items())
        return feat_value_pairs_str

    feat_value_pairs_baseline_only_str = get_feat_value_pairs_str(feat_value_pairs_baseline_only)
    feat_value_pairs_system_only_str = get_feat_value_pairs_str(feat_value_pairs_system_only)

    unshared_so_mask, unshared_bo_mask  = diac_mat_system_only != 0, diac_mat_baseline_only != 0
    unshared_so_mask_zero, unshared_bo_mask_zero  = diac_mat_system_only == 0, diac_mat_baseline_only == 0
    unshared_so_sum, unshared_bo_sum = np.sum(unshared_so_mask), np.sum(unshared_bo_mask)
    num_lemmas_valid_so = np.sum(np.any(unshared_so_mask, axis=1))
    num_lemmas_valid_bo = np.sum(np.any(unshared_bo_mask, axis=1))
    num_feats_valid_so = np.sum(np.any(unshared_so_mask, axis=0))
    num_feats_valid_bo = np.sum(np.any(unshared_bo_mask, axis=0))
    examples_str_so = generate_examples(index2lemmas_pos_so, index2analysis_so, unshared_so_mask)
    examples_str_bo = generate_examples(index2lemmas_pos_bo, index2analysis_bo, unshared_bo_mask)
    examples_str_so_zero = generate_examples(index2lemmas_pos_so, index2analysis_so, unshared_so_mask_zero)
    examples_str_bo_zero = generate_examples(index2lemmas_pos_bo, index2analysis_bo, unshared_bo_mask_zero)
    unshared_so_total = diac_mat_system_only.shape[0] * diac_mat_system_only.shape[1]
    unshared_bo_total = diac_mat_baseline_only.shape[0] * diac_mat_baseline_only.shape[1]

    if specific_feat_combs_system is not None:
        rows.append([0, '≥1\n(group 1)',
                f'{unshared_so_sum - group_2_sum_so:,}' + '\n' + f'({(unshared_so_sum - group_2_sum_so)/unshared_so_sum:.1%})',
                '-', '-', '-', feat_value_pairs_system_only_str])
        rows.append([0, '≥1\n(group 2)',
                bold(color(f'{group_2_sum_so:,}', 'orange')) + '\n' + bold(f'({group_2_sum_so/unshared_so_sum:.1%})'),
                '-', '-', '-', '(same as above)'])
    rows.append([0, '≥1\n(all)',
            f'{unshared_so_sum:,}' + '\n' + f'({unshared_so_sum/unshared_so_total:.1%})',
            f'{num_lemmas_valid_so:,}' + '\n' + f'({num_lemmas_valid_so/diac_mat_system_only.shape[0]:.1%})',
            f'{num_feats_valid_so:,}' + '\n' + f'({num_feats_valid_so/diac_mat_system_only.shape[1]:.1%})',
            examples_str_so, '-'])
    rows.append(['0\n(system)', '0\n(system)',
            f'{unshared_so_total - unshared_so_sum:,}' + '\n' + f'({(unshared_so_total - unshared_so_sum)/unshared_so_total:.1%})',
            '-', '-', examples_str_so_zero, '', ''])
    if specific_feat_combs_baseline is not None:
        rows.append(['≥1\n(group 1)', 0,
                f'{unshared_bo_sum - group_2_sum_bo:,}' + '\n' + f'({(unshared_bo_sum - group_2_sum_bo)/unshared_bo_sum:.1%})',
                '-', '-', '-', feat_value_pairs_baseline_only_str])
        rows.append(['≥1\n(group 2)', 0,
                bold(color(f'{group_2_sum_bo:,}', 'orange')) + '\n' + bold(f'({group_2_sum_bo/unshared_bo_sum:.1%})'),
                '-', '-', '-', '(same as above)'])
    rows.append(['≥1\n(all)', 0,
            f'{unshared_bo_sum:,}' + '\n' + f'({unshared_bo_sum/unshared_bo_total:.1%})',
            f'{num_lemmas_valid_bo:,}' + '\n' + f'({num_lemmas_valid_bo/diac_mat_baseline_only.shape[0]:.1%})',
            f'{num_feats_valid_bo:,}' + '\n' + f'({num_feats_valid_bo/diac_mat_baseline_only.shape[1]:.1%})',
            examples_str_bo, '-'])
    rows.append(['0\n(baseline)', '0\n(baseline)',
            f'{unshared_bo_total - unshared_bo_sum:,}' + '\n' + f'({(unshared_bo_total - unshared_bo_sum)/unshared_bo_total:.1%})',
            '-', '-', examples_str_bo_zero, '', ''])

    print(tabulate(rows, tablefmt='fancy_grid', headers=header,
                maxheadercolwidths=[13, 13, None, None, None, None, 50],
                maxcolwidths=[None, None, None, None, None, None, 50]))
    print()

    def section_unshared_group1_stats():
        print(bold(underline(f'Breakdown of the individually unseen feat:value pairs in the x-0 and 0-x cases (GROUP 1)')))
        notes = color(f"""
        Notes:
        - The below table breaks down the first group of unshared features (described above).
        - Feats column below is used differently than previous Feats columns and is used to specify the number of feature combinations in which
        the respective sub-combination happens. There IS overlap between feat:value pairs and the total should NOT sum to the total number of feature combinations
        in group 1 (contrary to next section). The percentages in this column do sum to 100%.
        - Percentages here for Slots and Feats are based on proportion of the total GROUP 1 counts.
        """, 'warning')
        print(notes)
        print()
        rows = []
        header = [f'# diac ({args.baseline_name})', f'# diac ({args.system_name})',
                'Features', 'Slots', 'Lemmas', 'Feats', 'Example']
        for i, specific_feat_combs in enumerate([feat_value_pairs_system_only, feat_value_pairs_baseline_only]):
            i = abs(i - 1)
            rows_ = []
            total_sum = 0
            index2lemmas_pos = index2lemmas_pos_so if i else index2lemmas_pos_bo
            analysis2index = analysis2index_so if i else analysis2index_bo
            index2analysis = index2analysis_so if i else index2analysis_bo
            group_2_categorization = group_2_categorization_so if i else group_2_categorization_bo
            diac_mat_ = diac_mat_system_only if i else diac_mat_baseline_only
            num_lemmas = diac_mat_system_only.shape[0] if i else diac_mat_baseline_only.shape[0]
            num_feats = diac_mat_system_only.shape[1] if i else diac_mat_baseline_only.shape[1]
            total_feat_combs_group2 = sum(len(feats) for feats in group_2_categorization.values())
            total_feat_combs = num_feats - total_feat_combs_group2

            total = unshared_so_sum - group_2_sum_so if i else unshared_bo_sum - group_2_sum_bo
            for feat, value, pos in specific_feat_combs:
                feat_value = f'{pos.upper()}(' + f'{feat}:{value}' + ')'
                feat_value_indexes_ = np.array([i for i, feat_comb in enumerate(index2analysis)
                                                if value == feat_comb[feat2index[feat]]])
                group_1_mask = diac_mat_[:, feat_value_indexes_] != 0
            
                match_comb_indexes = np.where(group_1_mask)
                match_comb_indexes = ([match_comb_indexes[0][0]], [feat_value_indexes_[match_comb_indexes[1][0]]])
                examples_str = generate_examples(index2lemmas_pos, index2analysis,
                                                match_comb_indexes=match_comb_indexes)
                
                num_slots = int(np.sum(group_1_mask))
                total_sum += num_slots
                num_lemmas_valid = int(np.sum(np.any(group_1_mask, axis=1)))
                num_feats_valid = len(feat_value_indexes_)
                
                row = [('0' if i else '≥1'), ('≥1' if i else '0'),
                    feat_value,
                    f'{num_slots:,}' + '\n' + f'({num_slots/total:.1%})',
                    f'{num_lemmas_valid:,}' + '\n' + f'({num_lemmas_valid/num_lemmas:.1%})',
                    f'{num_feats_valid:,}' + '\n' + f'({num_feats_valid/total_feat_combs:.1%})',
                    examples_str]
                rows_.append(row)
            
            rows += sorted(rows_, key=lambda row: int(row[3].split('\n')[0].replace(',', '')),
                        reverse=True)

        print(tabulate(rows, tablefmt='fancy_grid', headers=header,
                    maxheadercolwidths=[8, 7, None, None, None, None, 50],
                    maxcolwidths=[8, 7, None, None, None, None, 50]))
        print()


    def section_unshared_group2_stats():
        print(bold(underline(f'Breakdown of the (mappable, invalid, or missing) sub-combinations in the x-0 and 0-x cases (GROUP 2)')))
        notes = color(f"""
        Notes:
        - The below table breaks down the second group of unshared features (described above).
        - When all feature combinations that contain one of the unshared feat:value pairs are eliminated, we are left with three groups of feature sub-combinations:
            1. ones which can be mappable to feature combinations in the opposite system
            2. ones which should just not exist
            3. ones which are missing in the opposite system
        - Every single one of these feature combinations is accounted for automatically by elimination via human identification of the culprit feat:value
        pair(s) which make that feature combination not appear in the opposite system.
        - Feats column below is used differently than previous Feats columns and is used to specify the number of feature combinations in which
        the respective sub-combination happens. There is NO overlap between sub-combinations and the total SHOULD sum to the total number of feature combinations
        in group 2 (contrary to previous section).
        """, 'warning')
        print(notes)
        rows = []
        header = [f'# diac ({args.baseline_name})', f'# diac ({args.system_name})',
                'Features', 'Slots', 'Lemmas', 'Feats', 'Example', 'Explanation']
        for i, specific_feat_combs in enumerate([specific_feat_combs_system, specific_feat_combs_baseline]):
            i = abs(i - 1)
            rows_ = []
            total_sum = 0
            index2lemmas_pos = index2lemmas_pos_so if i else index2lemmas_pos_bo
            analysis2index = analysis2index_so if i else analysis2index_bo
            index2analysis = index2analysis_so if i else index2analysis_bo
            group_2_categorization = group_2_categorization_so if i else group_2_categorization_bo
            diac_mat_ = diac_mat_system_only if i else diac_mat_baseline_only
            num_lemmas = diac_mat_system_only.shape[0] if i else diac_mat_baseline_only.shape[0]
            num_feats = diac_mat_system_only.shape[1] if i else diac_mat_baseline_only.shape[1]
            total_feat_combs = sum(len(feats) for feats in group_2_categorization.values())
            feat_combs_indexes = feat_combs_indexes_so if i else feat_combs_indexes_bo
            total = int(np.sum(diac_mat_[:, feat_combs_indexes] != 0))
            for info in specific_feat_combs:
                unshared_feat_subcombs = ' '.join(sorted(f'{f}:{v}' for f, v in info['feats_dict'].items()))
                feat_combs_indexes_ = np.array([analysis2index[feats]
                                            for feats in group_2_categorization[unshared_feat_subcombs]])
                group_2_mask = diac_mat_[:, feat_combs_indexes_] != 0
            
                match_comb_indexes = np.where(group_2_mask)
                match_comb_indexes = ([match_comb_indexes[0][0]], [feat_combs_indexes_[0]])
                examples_str = generate_examples(index2lemmas_pos, index2analysis,
                                                match_comb_indexes=match_comb_indexes)
                num_slots = int(np.sum(group_2_mask))
                total_sum += num_slots
                num_lemmas_valid = int(np.sum(np.any(group_2_mask, axis=1)))
                num_feats_valid = len(group_2_categorization[unshared_feat_subcombs])
                
                row = [('0' if i else '≥1'), ('≥1' if i else '0'),
                    unshared_feat_subcombs,
                    f'{num_slots:,}' + '\n' + f'({num_slots/total:.1%})',
                    f'{num_lemmas_valid:,}' + '\n' + f'({num_lemmas_valid/num_lemmas:.1%})',
                    f'{num_feats_valid:,}' + '\n' + f'({num_feats_valid/total_feat_combs:.1%})',
                    examples_str, info['explanation']]
                rows_.append(row)
            
            rows += sorted(rows_, key=lambda row: int(row[3].split('\n')[0].replace(',', '')),
                        reverse=True)
            assert total == total_sum
            rows.append([('0' if i else '≥1'), ('≥1' if i else '0'),
                        bold(color('Total', 'orange')),
                        bold(color(f'{total_sum:,}', 'orange')) + '\n' + bold(f'({total_sum/total:.1%})'),
                        '-', '-', '-', '-'])

        print(tabulate(rows, tablefmt='fancy_grid', headers=header,
                    maxheadercolwidths=[8, 7, None, None, None, None, 50, 50],
                    maxcolwidths=[8, 7, None, None, None, None, 50, 50]))
        print()

    if specific_feat_combs_system is not None and specific_feat_combs_baseline is not None:
        section_unshared_group1_stats()
        section_unshared_group2_stats()


db_baseline_gen = MorphologyDB(args.db_baseline, flags='g')
generator_baseline = Generator(db_baseline_gen)

db_system_gen = MorphologyDB(args.db_system, flags='g')
generator_system = Generator(db_system_gen)

POS = eval_utils.get_pos(args.pos, db_baseline_gen, db_system_gen)
eval_utils.harmonize_defaults(generator_baseline._db, generator_system._db, POS)

try:
    results_debug_eval = eval_utils.load_results_debug_eval(args.report_dir)
except:
    pass

try:
    MATRICES = eval_utils.load_matrices(args.report_dir)

    info = MATRICES['intersection']
    diac_mat_baseline_inter = info['diac_mat_baseline']
    diac_mat_system_inter = info['diac_mat_system']
    system_only_mat_inter = info['system_only_mat']
    baseline_only_mat_inter = info['baseline_only_mat']
    no_intersect_mat_inter = info['no_intersect_mat']
    index2analysis_inter, analysis2index_inter = info['index2analysis'], info['analysis2index']
    index2lemmas_pos_inter = {index: lemma_pos for index, lemma_pos in info['lemmas_pos']}
    failed = info['failed'] if 'failed' in info else None

    info_bo = MATRICES['baseline_only']
    diac_mat_baseline_only = info_bo['diac_mat_baseline']
    index2analysis_bo, analysis2index_bo = info_bo['index2analysis'], info_bo['analysis2index']
    index2lemmas_pos_bo = {index: lemma_pos for index, lemma_pos in info_bo['lemmas_pos']}
    failed_bo = info_bo['failed'] if 'failed' in info_bo else None

    info_so = MATRICES['system_only']
    diac_mat_system_only = info_so['diac_mat_system']
    index2analysis_so, analysis2index_so = info_so['index2analysis'], info_so['analysis2index']
    index2lemmas_pos_so = {index: lemma_pos for index, lemma_pos in info_so['lemmas_pos']}
    failed_so = info_so['failed'] if 'failed' in info_so else None
    POS2FEAT_VALUE_PAIRS = eval_utils.load_pos2feat_value_pairs(args.report_dir)
except:
    print('WARNING: Script will not work as intended and might raise errors if all three splits are not present.')

db_baseline = MorphologyDB(args.db_baseline)
db_system = MorphologyDB(args.db_system)


if __name__ == '__main__':
    mask_not_equal_0_baseline = diac_mat_baseline_inter != 0
    mask_not_equal_0_system = diac_mat_system_inter != 0
    num_valid_feats = int(np.sum(np.any(diac_mat_system_inter|diac_mat_baseline_inter, axis=0)))
    num_valid_lemmas = int(np.sum(np.any(diac_mat_system_inter|diac_mat_baseline_inter, axis=1)))

    section_title()
    section_lemma_overlap()
    del db_baseline, db_system
    section_high_level_overlap_stats()
    section_shared_combinations_high_level_stats()
    section_x_y_breakdown()
    section_unshared_combinations_high_level_stats()