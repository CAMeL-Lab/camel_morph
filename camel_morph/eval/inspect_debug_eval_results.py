import sys
import argparse
import json
import os
import numpy as np
from tqdm import tqdm
from tabulate import tabulate
import itertools

import eval_utils
from eval_utils import color, bold, underline

parser = argparse.ArgumentParser()
parser.add_argument("-config_file", default='eval_files/report_default',
                    type=str, help="Config file specifying which sheets to use.")
parser.add_argument("-pos", required=True,
                    type=str, help="Part-of-speech to perform the evaluation on.")
parser.add_argument("-db_baseline", default='eval_files/calima-msa-s31_0.4.2.utf8.db',
                    type=str, help="Path of the MSA baseline DB file we will be comparing against.")
parser.add_argument("-db_system", default='databases/camel-morph-msa/XYZ_msa_all_v1.0.db',
                    type=str, help="Path of the MSA baseline DB file we will be comparing against.")
parser.add_argument("-report_dir", default='eval_files/report_default',
                    type=str, help="Paths of the directory containing partial reports generated by the full generative evaluation.")
parser.add_argument("-baseline_name", default='Calima',
                    type=str, help="Name that will appear in the report for the baseline.")
parser.add_argument("-system_name", default='Camel',
                    type=str, help="Name that will appear in the report for the system.")
parser.add_argument("-camel_tools", default='local', choices=['local', 'official'],
                    type=str, help="Path of the directory containing the camel_tools modules.")
args = parser.parse_args()

with open('configs/config_default.json') as f:
    config = json.load(f)

if args.camel_tools == 'local':
    camel_tools_dir = config['global']['camel_tools']
    sys.path.insert(0, camel_tools_dir)

from camel_tools.morphology.database import MorphologyDB
from camel_tools.morphology.generator import Generator
from camel_tools.utils.charmap import CharMapper

bw2ar = CharMapper.builtin_mapper('bw2ar')
ar2bw = CharMapper.builtin_mapper('ar2bw')

db_baseline_gen = MorphologyDB(args.db_baseline, flags='g')
generator_baseline = Generator(db_baseline_gen)

db_system_gen = MorphologyDB(args.db_system, flags='g')
generator_system = Generator(db_system_gen)

POS = eval_utils.get_pos(args.pos, db_baseline_gen, db_system_gen)
eval_utils.harmonize_defaults(generator_baseline._db, generator_system._db, POS)

try:
    results_debug_eval = eval_utils.load_results_debug_eval(args.report_dir)
except:
    pass

try:
    MATRICES = eval_utils.load_matrices(args.report_dir)
    info = MATRICES['intersection']
    diac_mat_baseline = info['diac_mat_baseline']
    diac_mat_system = info['diac_mat_system']
    system_only_mat = info['system_only_mat']
    baseline_only_mat = info['baseline_only_mat']
    no_intersect_mat = info['no_intersect_mat']
    index2analysis, analysis2index = info['index2analysis'], info['analysis2index']
    index2lemmas_pos = {index: lemma_pos for index, lemma_pos in info['lemmas_pos']}
    failed = info['failed'] if 'failed' in info else None
except:
    pass

def extract_examples(match_comb_mask):
    match_comb_indexes = np.where(match_comb_mask)
    example_coord = (match_comb_indexes[0][0], match_comb_indexes[1][0])
    lemma, pos = index2lemmas_pos[example_coord[0]]
    feats = index2analysis[example_coord[1]]
    try:
        example_forms_system = generator_system.generate(
            lemma, eval_utils.construct_feats(feats, pos))
        example_forms_system = ','.join(
            set(eval_utils.preprocess_lex_features(form, True)['diac']
                for form in example_forms_system))
    except:
        example_forms_system = ''
    try:
        example_forms_baseline = generator_baseline.generate(
            lemma, eval_utils.construct_feats(feats, pos), legacy=True)
        example_forms_baseline = ','.join(
            set(eval_utils.preprocess_lex_features(form, True)['diac']
                for form in example_forms_baseline))
    except:
        example_forms_baseline = ''

    examples_str = (bold(color('lex:', 'warning')) + ar2bw(lemma) + bold(color('x', 'fail')) + '\n' +
                   bold(color('feats:', 'warning')) + '+'.join(feats) + '\n' +
                   bold(color('system:', 'warning')) + ar2bw(example_forms_system) + bold(color('x', 'fail')) + '\n' +
                   bold(color('baseline:', 'warning')) + ar2bw(example_forms_baseline)) + bold(color('x', 'fail'))
    
    return examples_str


def generate_row_for_combination(combination, match_total):
    if len(combination) == 2:
        num_diac_baseline, num_diac_system = combination
    elif len(combination) == 3:
        num_diac_baseline, num_diac_system, _ = combination
    if combination == ('≥0', '≥0', '≥1'):
        match_comb_mask = (diac_mat_baseline != 0) | (diac_mat_system != 0)
    elif combination == ('≥1', '≥1'):
        match_comb_mask = (diac_mat_baseline != 0) & (diac_mat_system != 0)
    elif combination[0] == '≥1':
        match_comb_mask = (diac_mat_baseline != 0) & (diac_mat_system == num_diac_system)
    elif combination[1] == '≥1':
        match_comb_mask = (diac_mat_baseline == num_diac_baseline) & (diac_mat_system != 0)
    else:
        match_comb_mask = (diac_mat_baseline == num_diac_baseline) & (diac_mat_system == num_diac_system)
        
    num_lemmas_match = int(np.sum(np.any(match_comb_mask, axis=1)))
    num_feats_match = int(np.sum(np.any(match_comb_mask, axis=0)))
    match_comb_sum = int(np.sum(match_comb_mask))
    if match_comb_sum == 0:
        return []

    no_intersect = int(np.sum(no_intersect_mat[match_comb_mask]))
    exact_match_indexes = ((baseline_only_mat == 0) &
                           (system_only_mat == 0) &
                           (no_intersect_mat == False) &
                           match_comb_mask)
    exact_match_indexes_sum = int(np.sum(exact_match_indexes))
    exact_match = int(np.sum(diac_mat_system[exact_match_indexes]))
    system_superset_indexes = ((system_only_mat != 0) &
                              (baseline_only_mat == 0) &
                              match_comb_mask)
    system_superset_indexes_sum = int(np.sum(system_superset_indexes))
    if '≥1' not in combination and combination[0] >= combination[1]:
        assert system_superset_indexes_sum == 0
    if '≥1' not in combination and combination[1] > combination[0]:
        system_superset_ = np.minimum(diac_mat_system[system_superset_indexes],
                                    diac_mat_baseline[system_superset_indexes])
    else:
        system_superset_ = diac_mat_system[system_superset_indexes]
    system_superset = int(np.sum(system_superset_))
    baseline_superset_indexes = ((system_only_mat == 0) &
                                 (baseline_only_mat != 0) &
                                 match_comb_mask)
    baseline_superset_indexes_sum = int(np.sum(baseline_superset_indexes))
    if '≥1' not in combination and combination[1] >= combination[0]:
        assert baseline_superset_indexes_sum == 0
    baseline_superset = int(np.sum(diac_mat_system[baseline_superset_indexes]))
    intersect_indexes = ((baseline_only_mat != 0) &
                         (system_only_mat != 0) &
                         match_comb_mask)
    intersect_indexes_sum = int(np.sum(intersect_indexes))
    assert np.sum(system_only_mat[intersect_indexes]) == \
           np.sum(baseline_only_mat[intersect_indexes])
    intersect = int(np.sum(system_only_mat[intersect_indexes]))
    if '≥1' not in combination:
        if combination[0] == combination[1]:
            assert exact_match == \
            np.sum(diac_mat_baseline[exact_match_indexes]) == \
            exact_match_indexes_sum * combination[0] == \
            exact_match_indexes_sum * combination[1]
            assert system_superset == baseline_superset == 0
        else:
            assert exact_match == 0
    coverage_total_x_y = int(
        no_intersect + exact_match + system_superset +
        baseline_superset + intersect)
    
    examples_str = extract_examples(match_comb_mask)

    if coverage_total_x_y:
        coverage_x_y_dist = [no_intersect/coverage_total_x_y ,
                            exact_match/coverage_total_x_y,
                            baseline_superset/coverage_total_x_y,
                            system_superset/coverage_total_x_y,
                            intersect/coverage_total_x_y]
    else:
        coverage_x_y_dist = [no_intersect, exact_match, baseline_superset,
                             system_superset, intersect]
    slot_total_x_y = (no_intersect + exact_match_indexes_sum +
                      baseline_superset_indexes_sum +
                      system_superset_indexes_sum +
                      intersect_indexes_sum)
    assert slot_total_x_y == match_comb_sum
    slot_x_y_dist = [no_intersect/slot_total_x_y,
                     exact_match_indexes_sum/slot_total_x_y,
                     baseline_superset_indexes_sum/slot_total_x_y,
                     system_superset_indexes_sum/slot_total_x_y,
                     intersect_indexes_sum/slot_total_x_y]
    coverage_highest_index = np.array(coverage_x_y_dist).argmax()
    slot_highest_index = np.array(slot_x_y_dist).argmax()
    coverage_x_y_dist_str = [
        (f'{x:.1%}' if i != coverage_highest_index else bold(color(f'{x:.1%}', 'green'))) +
        ((f'\n{y:.1%}' if i != slot_highest_index else '\n' + bold(color(f'{y:.1%}', 'cyan'))) if x != y else '')
        for i, (x, y) in enumerate(zip(coverage_x_y_dist, slot_x_y_dist))]

    total_diac_baseline = int(np.sum(diac_mat_baseline[match_comb_mask]))
    total_diac_system = int(np.sum(diac_mat_system[match_comb_mask]))
    if '≥1' not in combination:
        assert slot_total_x_y * combination[0] == total_diac_baseline
    if total_diac_baseline != 0 and total_diac_system != 0:
        recall_diac = (coverage_total_x_y - no_intersect) / total_diac_baseline
        recall_slot = (slot_total_x_y - no_intersect) / match_comb_sum
        recall_diac_str, recall_slot_str = f'{recall_diac:.1%}', f'{recall_slot:.1%}'
    else:
        recall_diac, recall_slot = 'N/A', 'N/A'
        recall_diac_str, recall_slot_str = recall_diac, recall_slot

    return [combination[0], combination[1],
            f'{match_comb_sum:,}' + '\n' + f'({match_comb_sum/match_total:.1%})',
            f'{num_lemmas_match:,}' + '\n' + f'({num_lemmas_match/num_valid_lemmas:.1%})',
            f'{num_feats_match:,}' + '\n' + f'({num_feats_match/num_valid_feats:.1%})',
            examples_str,
            *coverage_x_y_dist_str,
            bold(color(recall_diac_str, 'blue')) +
            (('\n' + bold(color(recall_slot_str, 'blue')) if recall_diac != recall_slot else ''))]


db_baseline = MorphologyDB(args.db_baseline)
if args.pos == 'other':
    POS = sorted(pos for pos in db_baseline.defaults
                 if pos not in ['verb', 'noun', 'noun_quant', 'noun_num', 'noun_prop',
                                'adj', 'adj_num', 'adj_comp', None])
else:
    POS = [args.pos]

report_title = f"Evaluation Report - {' '.join(pos.upper() for pos in POS)}"
try:
    terminal_size_col = os.get_terminal_size().columns
except:
    terminal_size_col = len(report_title)
print()
print('=' * terminal_size_col)
print(report_title)
print('=' * terminal_size_col)
print()
baseline_path = color(bold(args.db_baseline), 'cyan')
system_path = color(bold(args.db_system), 'cyan')
print(bold(underline('DBs used for analysis')))
print(f'{args.baseline_name}: ' + color(bold(args.db_baseline), 'cyan'))
print(f'{args.system_name}: ' + color(bold(args.db_system), 'cyan'))
print()
print(bold(underline(f'Verb Lemmas overlap between {args.baseline_name} and {args.system_name}')))
print()
lemmas_pos_baseline = eval_utils.get_all_lemmas_from_db(db_baseline)
del db_baseline
lemmas_baseline = set([lemma_pos[0] for lemma_pos in lemmas_pos_baseline if lemma_pos[1] in POS])
lemmas_pos_system = eval_utils.get_all_lemmas_from_db(MorphologyDB(args.db_system))
lemmas_system = set([lemma_pos[0] for lemma_pos in lemmas_pos_system if lemma_pos[1] in POS])
rows = []
header = ['A . B', 'Result', '# lemmas', '(%)', 'Lemmas']
lemmas_baseline_only = lemmas_baseline - lemmas_system
lemmas_system_only = lemmas_system - lemmas_baseline
lemmas_intersect = lemmas_system & lemmas_baseline
lemmas_union = lemmas_system | lemmas_baseline
rows.append([f'{args.baseline_name} - {args.system_name}',
             f'{len(lemmas_baseline_only):,}',
             f'{len(lemmas_baseline):,} in A',
             f'{len(lemmas_baseline_only) / len(lemmas_baseline):.2%}',
             ' '.join(sorted(map(ar2bw, lemmas_baseline_only)))])
rows.append([f'{args.system_name} - {args.baseline_name}',
             f'{len(lemmas_system_only):,}',
             f'{len(lemmas_system):,} in A',
             f'{len(lemmas_system_only) / len(lemmas_system):.2%}',
             ' '.join(sorted(map(ar2bw, lemmas_system_only)))])
rows.append([f'{args.system_name} ∩ {args.baseline_name}',
             bold(color(f'{len(lemmas_intersect):,}', 'green')),
             f'{len(lemmas_union):,} in A ∪ B',
             f'{len(lemmas_intersect) / len(lemmas_union):.2%}',
             '-'])
print(tabulate(rows, tablefmt='fancy_grid', headers=header, maxcolwidths=[None, None, None, None, 100]))
print()
print(bold(underline(f'Overlap statistics of generated diacs between {args.baseline_name} and {args.system_name}')))
print()

mask_not_equal_0_baseline = diac_mat_baseline != 0
mask_not_equal_0_system = diac_mat_system != 0

rows = []
num_valid_feats = int(np.sum(np.any(diac_mat_system|diac_mat_baseline, axis=0)))
num_valid_lemmas = int(np.sum(np.any(diac_mat_system|diac_mat_baseline, axis=1)))
slots_total = num_valid_feats * num_valid_lemmas
slots_filled_mask = mask_not_equal_0_system | mask_not_equal_0_baseline
slots_filled_total = int(np.sum(slots_filled_mask))

examples_str = extract_examples(slots_filled_mask)
rows.append(['Number of slots filled by at least one of the systems (0-x, x-0, x-y)',
             bold(color(f'{slots_filled_total:,}', 'warning')),
             f'{slots_filled_total/slots_total:.0%}',
             examples_str])
examples_str = extract_examples(~slots_filled_mask)
rows.append(['Number of slots filled by none of the systems (0-0)',
             f'{slots_total - slots_filled_total:,}',
             f'{(slots_total - slots_filled_total)/slots_total:.0%}',
             examples_str])
rows.append(['Total number of slots per system',
             f'{slots_total:,}' + '\n(' + bold(color(f'{num_valid_lemmas:,} ', 'green')) + '× ' +
             bold(color(f'{num_valid_feats:,}', 'green')) + ')',
             f'{1:.0%}', '-'])
assert len(diac_mat_baseline) == len(diac_mat_system)
print('Number of lemmas evaluated on: ' + bold(color(f'{len(diac_mat_baseline):,}', 'green')) +
      f' ({args.system_name} ∩ {args.baseline_name})')
print('Total number of feature combinations across both systems: ' + bold(color(f'{num_valid_feats:,}', 'green')))
print(tabulate(rows, tablefmt='fancy_grid', maxcolwidths=[40, None, None, 40]))
print()
print(bold(underline(f'Distribution of feature combination availability across systems (0-x, x-0, x-y)')))

notes = color(f"""
Notes:
    - # diac here is the number of unique diacs generated, and not the number of analyses generated which could generally be more.
    - The meaning of the dash ("-") is anything but zero.
    - A "slot" is a matrix cell representing a lemma and a feature combinatinon from which one a more diacs were generated.
    - "Slot space" means we are counting number of slots while in diac space were are counting number of diacs. This effectively means that
    the # diac is taken as 1 for the purpose of recall analysis.
    - Slots column is the number of feature combinations that both systems were able to generate for listed lemmas with the specified number of diacs.
    - Lemmas column is the number of lemmas with which at least one feature combination generates with the specified number of diacs.
    - Top number in recall distribution (last columns) indicates recall (diac space) by {args.system_name} of {args.baseline_name} and bottom is in slot space
      (displayed only if different). Total recall in slot space basically represents the sum of all categories (in slot space) minus no_intersect.
    - All total recall values are micro-averaged.
""", 'warning')
print(notes)
print()
match_x_y_total = int(np.sum(mask_not_equal_0_baseline & mask_not_equal_0_system))
match_total = int(np.sum(mask_not_equal_0_baseline | mask_not_equal_0_system))

rows = []
header = [f'# diac ({args.baseline_name})', f'# diac ({args.system_name})',
          'Slots', 'Lemmas', 'Feat combs', 'Example', 'Recall']

combinations = [(0, '≥1'), ('≥1', 0), ('≥1', '≥1'), ('≥0', '≥0', '≥1')]
for combination in tqdm(combinations, ncols=100):
    row = generate_row_for_combination(combination, match_total)
    if row:
        rows.append(row)

rows = sorted(rows, key=lambda row: int(row[2].split('\n')[0].replace(',', '')) if row[0] != '≥0' else -1,
              reverse=True)
rows = [row[:6] + row[11:] for row in rows]
match_x_y_index = [i for i, row in enumerate(rows) if row[0] == row[1] == '≥1'][0]
match_all_index = [i for i, row in enumerate(rows) if row[0] == row[1] == '≥0'][0]
rows[match_x_y_index][2] = (bold(color(rows[match_x_y_index][2].split('\n')[0], 'cyan')) + '\n' +
                            bold(rows[match_x_y_index][2].split('\n')[1]))
rows[match_x_y_index][3] = (bold(color(rows[match_x_y_index][3].split('\n')[0], 'orange')) + '\n' +
                            bold(rows[match_x_y_index][3].split('\n')[1]))
rows[match_x_y_index][4] = (bold(color(rows[match_x_y_index][4].split('\n')[0], 'orange')) + '\n' +
                            bold(rows[match_x_y_index][4].split('\n')[1]))
rows[match_all_index][2] = (bold(color(rows[match_all_index][2].split('\n')[0], 'warning')) + '\n' +
                            bold(rows[match_all_index][2].split('\n')[1]))
rows[match_all_index][3] = (color(rows[match_all_index][3].split('\n')[0], 'green') + '\n' +
                            bold(rows[match_all_index][3].split('\n')[1]))
rows[match_all_index][4] = (color(rows[match_all_index][4].split('\n')[0], 'green') + '\n' +
                            bold(rows[match_all_index][4].split('\n')[1]))
rows[match_all_index][-1] = bold(color('N/A', 'blue'))
rows[-1] = [bold(v) for v in rows[-1]]

print(tabulate(rows, tablefmt='fancy_grid', headers=header,
               maxheadercolwidths=[8, 7, None, None, 7, 40, None]))

print()
print(bold(underline(f'Breakdown of the x-y set (coverage of {args.baseline_name} by {args.system_name})')))
print()
num_diac_baseline_possible, num_diac_system_possible = [], []
for x in range(1, np.max(diac_mat_baseline) + 1):
    if x in diac_mat_baseline:
        num_diac_baseline_possible.append(x)
for x in range(1, np.max(diac_mat_baseline) + 1):
    if x in diac_mat_system:
        num_diac_system_possible.append(x)

rows = []
header = [f'# diac ({args.baseline_name})', f'# diac ({args.system_name})',
          'Slots', 'Lemmas', 'Feat combs', 'Example', 'No intersec', 'Exact match',
          f'{args.baseline_name} super', f'{args.system_name} super', 'Intersec', 'Recall (micro)']

combinations = list(itertools.product(num_diac_baseline_possible, num_diac_system_possible))
combinations.append(('≥1', '≥1'))
for combination in tqdm(combinations, ncols=100):
    row = generate_row_for_combination(combination, match_x_y_total)
    if row:
        rows.append(row)

rows = sorted(rows, key=lambda row: int(row[2].split('\n')[0].replace(',', '')) if row[0] != '≥1' else -1,
              reverse=True)
rows[-1][2] = bold(color(rows[-1][2].split('\n')[0], 'cyan')) + '\n' + \
              bold(rows[-1][2].split('\n')[1])
rows[-1][3] = bold(color(rows[-1][3].split('\n')[0], 'orange')) + '\n' + \
              bold(rows[-1][3].split('\n')[1])
rows[-1][4] = bold(color(rows[-1][4].split('\n')[0], 'orange')) + '\n' + \
              bold(rows[-1][4].split('\n')[1])
rows[-1] = [bold(v) for v in rows[-1]]
print(tabulate(rows, tablefmt='fancy_grid', headers=header,
               maxheadercolwidths=[8, 7, None, None, 9, 40, 8, 7, 8, 7, 8, None],
               maxcolwidths=[8, 7, None, None, 9, 40, 8, 7, 8, 7, 8, None]))

print()